---
title: "Final"
author: "roberta"
date: "16/01/2021"
output: html_document
---

```{r}
library(tidyverse)
library(dplyr)
library(sf)
library(stringr)
library(tmap)
library(classInt)
library(broom)
library(corrplot)
library(spdep)

```


```{r}
CB = read_csv('./../Boston/Certified Businesses.csv')
sf_boston = sf::read_sf('./ZIP_Codes-shp/ZIP_Codes.shp')
pop = read_csv('./population_by_zip.csv')
```
```{r}
plot(sf_boston[sf_boston$ZIP5 == '02467',]['ZIP5'])

# 
zip2467 = st_combine(sf_boston[sf_boston$ZIP5 == '02467',])
zip_rest = sf_boston[!sf_boston$ZIP5 == '02467',]

# create sf object from combined polugons
sf_object = zip2467 %>% st_sf %>% st_cast

# add all the rows
sf_object$OBJECTID = 37
sf_object$ZIP5 = '02467'
sf_object$ShapeSTAre = NA
sf_object$ShapeSTLen = NA


# join back together
zip_codes = rbind(zip_rest, sf_object, deparse.level = 1)
plot(zip_codes['ZIP5'])
```

```{r}

# Create lists of what we want to keep
li1 = c('Boston', 'East Boston', 'South Boston')
li2 = c('WBE', 'MWBE')

# choose the rows that fits the lists
CB1 = CB[CB$city %in% li1,]

# create column with gender
CB1$sex = 'male'
CB1$sex[which(CB1$mbe_wbe_cert %in% li2)] = 'female'

# Choose just the columns we need
CB2 = CB1 %>% select(sex, zipcode)

# making female
female = CB2[CB2$sex == 'female',]
# get rid of those that has na in zipcode
female = female[!is.na(female$zipcode),]
# fix the zipcodes in the rows 28 and 45
female$zipcode[45] = '02127'
female$zipcode[28] = '02113'

# making male dataset
male = CB2[CB2$sex == 'male',]
```

```{r}
grouped_female = female %>% 
   select(zipcode) %>% # select only the columns we need
   group_by(zipcode) %>% # group by ZIP code - we want a number of bussinesses in each area
   summarise(count_female = n() ) %>% # sumarize the number of rows grouped by each zip code
   mutate(freq_female = count_female / sum(count_female)) # calculate new column that gives us freqency of bussinesses on the top of it

grouped_male = male %>% 
   select(zipcode) %>% # select only the columns we need
   group_by(zipcode) %>% # group by ZIP code - we want a number of bussinesses in each area
   summarise(count_male = n() ) %>% # sumarize the number of rows grouped by each zip code
   mutate(freq_male = count_male / sum(count_male)) # calculate new column that gives us freqency of bussinesses on the top of it

knitr::kable(head(grouped_female))
```
```{r}
data = merge(zip_codes, grouped_male, how = 'left', by.x = "ZIP5", by.y = "zipcode",all.x= TRUE)
data = merge(data, grouped_female, how = 'left', by.x = "ZIP5", by.y = "zipcode" ,all.x= TRUE)
data = merge(data, pop, how = 'left', by.x = "ZIP5", by.y = "Zip Code" ,all.x= TRUE)


#data$count_male[is.na(data$count_male)] = 0
#data$count_female[is.na(data$count_female)] = 0
#data$freq_male[is.na(data$freq_male)] = 0
#data$freq_female[is.na(data$freq_female)] = 0
data$diff = abs(data$count_female - data$count_male)
data$diff_fr = abs(data$freq_female - data$freq_male)
data$female_buss_per_capita = (data$count_female/(data$Population_estimate_2019/1000))

data$male_buss_per_capita = (data$count_male/(data$Population_estimate_2019/1000))
```

```

```

```{r}
library(default)
plot(data["freq_male"], breaks = "quantile", nbreaks = 7)
plot(data["freq_female"], breaks = "quantile", nbreaks = 7)
plot(data["diff_fr"], breaks = "quantile", nbreaks = 7)
```

## ggplot

```{r, message=FALSE, warning=FALSE}
library(classInt)

# get quantile breaks
breaks_qt <- classIntervals(data$diff_fr, n = 4, style = "quantile")

# new dataset with breaks
data_br <- mutate(data, diff_cat = cut(diff_fr, breaks_qt$brks))

```

```{r}
ggplot() +
   geom_sf(data = data_br, aes(fill = diff_cat)) + 
   scale_fill_brewer(palette = "Greens") + # reverse palette with , direction = -1
   theme_void()
```

## tmap

```{r}
tm_shape(data)+
  tm_fill("freq_male",
          n = 4,
          style = "quantile", 
          palette = "Blues",
          legend.hist = TRUE,) +
   tm_compass(type="8star", size = 2) +
  tm_scale_bar(width = 0.15) +
  tm_borders(alpha = 0.5)

tm_shape(data)+
  tm_fill("freq_female",
          n = 4,
          style = "quantile", 
          palette = "Reds",
          legend.hist = TRUE,) +
   tm_compass(type="8star", size = 2) +
  tm_scale_bar(width = 0.15) +
  tm_borders(alpha = 0.5)

tm_shape(data)+
  tm_fill("diff_fr",
          n = 4,
          style = "quantile", 
          palette = "Greens",
          legend.hist = TRUE,) +
   tm_compass(type="8star", size = 2) +
  tm_scale_bar(width = 0.15) +
  tm_borders(alpha = 0.5) 

tm_shape(data)+
  tm_fill("female_buss_per_capita",
          n = 4,
          style = "quantile", 
          palette = "Oranges",
          legend.hist = TRUE,) +
   tm_compass(type="8star", size = 2) +
  tm_scale_bar(width = 0.15) +
  tm_borders(alpha = 0.5) 


tm_shape(data)+
  tm_fill("male_buss_per_capita",
          n = 4,
          style = "quantile", 
          palette = "Blues",
          legend.hist = TRUE,) +
   tm_compass(type="8star", size = 2) +
  tm_scale_bar(width = 0.15) +
  tm_borders(alpha = 0.5)
```
```
# histograms

```{r}
```{r}
#Kernel density
plot(density(data$freq_male, na.rm = TRUE))
plot(density(data$freq_female, na.rm = TRUE))
plot(density(data$diff_fr, na.rm = TRUE))
plot(density(data$female_buss_per_capita, na.rm = TRUE))
plot(density(data$male_buss_per_capita, na.rm = TRUE))
```
```

```{r}
```{r}
q <- qplot(x = `freq_female`, 
           y = `freq_male`, 
           data=data)

#plot with a regression line; added some jitter here as the x-scale is rounded
q + stat_smooth(method="lm", se=FALSE, size=1) + 
  geom_jitter()
```
```

```{r}
```{r}
library(spatstat)
library(here)
library(sp)
library(rgeos)
library(maptools)
library(GISTools)
library(tmap)
library(geojson)
library(geojsonio)
library(tmaptools)
library(readr)
library(dplyr)
```


```{r}
shop_polygon <- sf::read_sf("./Boston/shop_polygon.geojson")
shop_point <- sf::read_sf("./Boston/shop_point.geojson")
sf_boston = sf::read_sf('./Zip_Codes-shp./ZIP_Codes.shp')
pop = read_csv('./population_by_zip.csv')

```
```{r}
plot(shop_polygon)
plot(shop_point)   #using just point data due to more accurate map points visualisation
```



```{r}
#tm_shape(sf_boston) +
#tm_polygons(col = NA, alpha = 0.5) +
#tm_shape(shop_polygon) +
  #tm_dots(col = "blue")

sp <- tm_shape(sf_boston) +
  tm_polygons(col = NA, alpha = 0.5) +
tm_shape(shop_point) +
  tm_dots(col = "blue")
sp
```

```{r}
shops = shop_point <- sf::read_sf("./Boston/shop_point.geojson")
sf_boston = sf::read_sf('./Zip_Codes-shp./ZIP_Codes.shp')
head(shops)
```
```{r}
#shops$addr.postcode[90] = '02134'
#shops$addr.postcode[93] = '02186'

```

```{r fig.width=15, fig.height=15, echo=FALSE}
ggplot(data = sf_boston) +
   geom_sf( aes( fill =ZIP5)) +  
   geom_sf(data = shops, size = 2) +
   theme_void() 


sum(grouped_shops$count_shop)
```

```{r}
# select the columns we need
shops = shops[,c('shop','geometry')]

# make a spatial join to gete the zip information to shops
x = st_join(shops, sf_boston, left= TRUE)

# aggregate the shops by zip codes
grouped_shops = x %>% 
   st_drop_geometry() %>%
   dplyr::select(ZIP5) %>% # select only the columns we need
   group_by(ZIP5) %>% # group by ZIP code - we want a number of bussinesses in each area
   summarise(count_shop = n() ) %>% # sumarize the number of rows grouped by each zip code
   mutate(freq_shop = count_shop / sum(count_shop)) # calculate new column that gives us freqency of bussinesses on the top of it

# join to the data
data = merge(data, grouped_shops, how = 'left', by = "ZIP5" ,all.x= TRUE)

# calculate per capita
data$shop_per_capita = (data$count_shop/(data$Population_estimate_2019/1000))

# look at the data
knitr::kable(head(data))
```


```{r}
# aggregate the shops by zip codes
grouped_shops = x %>% 
   st_drop_geometry() %>%
   dplyr::select(ZIP5)  %>% # select only the columns we need
   group_by(ZIP5)  %>% # group by ZIP code - we want a number of bussinesses in each area
   summarise(count_shop = n() ) %>% # sumarize the number of rows grouped by each zip code  n- calling rows
   mutate(freq_shop = count_shop / sum(count_shop)) # calculate new column that gives us freqency of bussinesses on the top of it
```
```{r}
sum(shops_2$count_shop)
```
```{r}
# join to the data
data = merge(data, grouped_shops, how = 'left', by = "ZIP5" ,all.x= TRUE)

# calculate per capita
data$shop_per_capita = (data$count_shop/(data$Population_estimate_2019/1000))

# look at the data
knitr::kable(head(data))
```

```{r}
tm_shape(data)+
  tm_fill("freq_female",
          n = 4,
          style = "quantile", 
          palette = "Purples",
          legend.hist = TRUE,) +
   tm_compass(type="8star", size = 2) +
  tm_scale_bar(width = 0.15) +
  tm_borders(alpha = 0.5) 

tm_shape(data)+
  tm_fill("freq_male",
          n = 4,
          style = "quantile", 
          palette = "Blues",
          legend.hist = TRUE,) +
   tm_compass(type="8star", size = 2) +
  tm_scale_bar(width = 0.15) +
  tm_borders(alpha = 0.5)

tm_shape(data)+
  tm_fill("freq_shop",
          n = 4,
          style = "quantile", 
          palette = "Oranges",
          legend.hist = TRUE,) +
   tm_compass(type="8star", size = 2) +
  tm_scale_bar(width = 0.15) +
  tm_borders(alpha = 0.5)
```

# Thinking of regression

#We need to ask ourself question based on our original hypothesis:

#> What are the factors that infulece the Number of women/men bussinesses?

#Does geographical business agglomeration impact the inclusivity of female entrepreneurs? Boston case? 

#x ~ y

#accessibility to bussiness ~ sex

```{r}
# indexing
# data[rows, columns]
data[5,4] # by number
grouped_female[5, c( 'count_female', 'zipcode')] # by column

# logic

grouped_female$zipcode == '02108'

grouped_female[grouped_female$zipcode == '02108' | grouped_female$zipcode == '02109',] # & = and , | = OR

# using lists

list1 = c('02108', '02108')

grouped_female[grouped_female = list1,]

data[is.na(data)] == 0
```



#2nd the higher the freq of female business is the less number of shops in zipcode area  slight , seem to be slightly negative 
#slightly negative with male relationship


```{r}
library(data.table)
data_recoded <- copy(data)
#########data_recoded = nafill(data_recoded, fill = 0)
#data_recoded[ , 5:18] <- apply(data_recoded[, 5:18], FUN = as.numeric, MARGIN=2)  #https://www.guru99.com/r-apply-sapply-tapply.html   function to apply for multiple elements
names(data_recoded)
```

```{r}

data_recoded[is.na(data_recoded)] = 0

q1 <- qplot(x = `freq_female`, 
           y = `freq_male`, 
           data=data_recoded)

q2 <- qplot(x = `freq_female`, 
           y = `freq_shop.x`, 
           data=data_recoded)

q3 <- qplot(x = `freq_male`, 
           y = `freq_shop.x`, 
           data=data_recoded)

#plot with a regression line - note, I've added some jitter here as the x-scale is rounded
q1 + stat_smooth(method="lm", se=FALSE, size=1) + 
  geom_jitter()
#plot with a regression line - note, I've added some jitter here as the x-scale is rounded
q2 + stat_smooth(method="lm", se=FALSE, size=1) + 
  geom_jitter()

q3 + stat_smooth(method="lm", se=FALSE, size=1) +        #######plot with regression line not regression module
  geom_jitter()

#the strong postive relationship; 60degreecloser    
# if area had a 0 and after manipulation it went from negatve to positive. we would expect the same results in rela life, rather than lesss businesses. using the 0 in regressions 
```


```{r}
plot(density(data$freq_female, na.rm = TRUE))
plot(density(data$freq_male, na.rm = TRUE))   #https://www.r-bloggers.com/2012/09/histogram-density-plot-combo-in-r/ plot density with 
                                                                 #histogram
plot(density(data$freq_shop, na.rm = TRUE))
plot(density(data$Population_estimate_2019))
```

```{r}
# running Regression

## Does it satisfy the 3 assumptions of regression?

#1. Are variables normally distributed? 
#2. Are residuals normally distributed?
#3. are the variables independent of each other? (multicolinearity)
```

```{r}
# 1. Are variables normally distributed? 
plot(density(data$freq_female, na.rm = TRUE))
plot(density(data$freq_male, na.rm = TRUE))
plot(density(data$freq_shop, na.rm = TRUE))
plot(density(data$Population_estimate_2019))

plot(density(log(data$freq_female), na.rm = TRUE))
plot(density(log(data$freq_male), na.rm = TRUE))
plot(density(log(data$freq_shop), na.rm = TRUE))
plot(density(log(data$Population_estimate_2019))
```

```{r}
model1 = lm(freq_female ~ freq_shop + Population_estimate_2019, data = data)
model2 = lm(freq_male ~ freq_shop + Population_estimate_2019, data = data)
summary(model1)
summary(model2)
```
```{r}
model1 = lm(log(freq_female) ~ log(freq_shop) + Population_estimate_2019, data = data)
model2 = lm(log(freq_male) ~ log(freq_shop) + Population_estimate_2019, data = data)
summary(model1)
summary(model2)
```

```{r}
# 2. Are residuals normally distributed?
plot(density(model1$residuals))
plot(density(model2$residuals))
```
```{r}
#3. are the variables independent of each other? (multicolinearity)
library(corrplot)
d = data[,c('freq_male','freq_female','freq_shop','Population_estimate_2019' )]
st_geometry(d) <- NULL

M<-cor(d,  use = "pairwise.complete.obs")
corrplot(M)

```

# Spatial autocorrelation


# Thinking of regression

We need to ask ourself question based on our original hypothesis:

> What are the factors that infulece the Number of women/men bussinesses?

Does geographical business agglomeration impact the inclusivity of female entrepreneurs? Boston case? 

x ~ y


# running Regression

## Does it satisfy the 3 assumptions of regression?

1. Are variables normally distributed? 
2. Are residuals normally distributed?
3. are the variables independent of each other? (multicolinearity)

```{r}
# Spatial autocorrelation
```{r}
# create extra dataset with only those things we need
data2 = data %>% 
   select(ZIP5, count_female, count_male, count_shop, geometry) %>% 
   mutate(area = st_area(.)) %>% 
   mutate(density_shop = count_shop/area) %>% 
   mutate(density_female = count_female/area) %>% 
   mutate(density_male = count_male/area) 

# For the spatial weights, we will need to substitue the NA with 0
data2$density_male[is.na(data2$density_male)] = 0
data2$density_female[is.na(data2$density_female)] = 0
data2$density_shop[is.na(data2$density_shop)] = 0
```

```{r}
#First calculate the centroids of all Wards in London
coordsW <- data2 %>%
  st_centroid() %>%
  st_geometry()
  
plot(coordsW,axes=TRUE)

#create a neighbours list
boston_nb <- data2 %>%
  poly2nb(., queen=T, snap = 0.03) # 10 = decimal degrees as your original data are in WGS84 - might want to convert to BNG and set a reasonable small distance in metres to snap. You'll need to experiment at bit, but 10 decimal degrees in the quick and dirty example above seems to generate something approximating an expected neighbours list.

#plot them
plot(boston_nb, st_geometry(coordsW), col="red")
#add a map underneath
plot(data$geometry, add=T)

#create a spatial weights object from these weights
boston_lw <-  nb2listw(boston_nb, style="C")

head(boston_lw$neighbours)
```

```{r}
# or it can be done as;

#Coerce sf into sp
data3 <- as(data2, "Spatial")
#Generate list of neighbours using the Queen criteria
w <- poly2nb(data3, row.names=data2$ZIP5, queen=T,  snap = 0.03)
#Generate list with weights using row standardisation
ww <-  nb2listw(w, style='W', zero.policy=TRUE)

#plot them
plot(w, st_geometry(coordsW), col="red")
#add a map underneath
plot(data$geometry, add=T)
```

```{r}
# include spatial lag for desired variable into dataset - this will help us to do regression
data3$lag_female = lag.listw(ww, as.numeric(data3$density_female))

# Morans I
moran.test(as.numeric(data2$density_female),ww)


moran.plot(as.numeric(data2$density_female), ww)
```

```{r}
#use the localmoran function to generate I for each ward in the city
lisa1 <- localmoran(as.numeric(data2$density_female), ww)
summary(locm_bm)

# get to our polugon data
moran.map <- cbind(data3, lisa1)

# plot
tm_shape(moran.map) +
  tm_fill(col = "Ii",
          style = "quantile",
          title = "local moran statistic")
```

```{r}
# plot LISA clustures

quadrant <- vector(mode="numeric",length=nrow(lisa1))

# centers the variable of interest around its mean
centred_female <- as.numeric(data2$density_female) - mean(as.numeric(data2$density_female))

# centers the local Moran's around the mean
m.local <- lisa1[,1] - mean(lisa1[,1])    

# significance threshold
signif <- 0.1 

# builds a data quadrant
quadrant[centred_female >0 & m.local>0] <- 4  
quadrant[centred_female <0 & m.local<0] <- 1      
quadrant[centred_female <0 & m.local>0] <- 2
quadrant[centred_female >0 & m.local<0] <- 3
quadrant[lisa1[,5]>signif] <- 0   

# plot in r
brks <- c(0,1,2,3,4)
colors <- c("white","blue",rgb(0,0,1,alpha=0.4),rgb(1,0,0,alpha=0.4),"red")
plot(data3,border="lightgray",col=colors[findInterval(quadrant,brks,all.inside=FALSE)])
box()
legend("bottomleft", legend = c("insignificant","low-low","low-high","high-low","high-high"),
       fill=colors,bty="n")
```

## Spatial Non-stationarity and Geographically Weighted Regression Models (GWR)





```

```

